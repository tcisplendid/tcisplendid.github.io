---
title: 学习算法
tags:
---

学习算法的初衷主要是因为面试，但是比起刷更多的难题，我希望能梳理基础和经典的算法之余，也探索解决算法问题的思维过程。

## 从问题与解开始
我们遇见的算法问题，通常可以分成三个部分：
1. 穷举/遍历问题：这是计算机主要增强人类能力的地方，所以大部分算法归根到底都有无法避开的穷举/遍历的环节，遍历输入，或者穷举输出（解空间）。
2. 数学问题：用“数学”是指分析问题特性、进行演绎推理、发现一些必然的结论，而这必然的结论会使问题归约为一个相对或者非常简单的问题。譬如说对等差数列求和，当然可以遍历，但是归约为一个公式能极大简化计算（O(n)到O(1))。
3. 设计问题：有时候解决方案必须考虑问题描述之外的一些因素，包括输入异常、计算资源、兼容性、代码的可读性、问题可能的变化等等。

我们的心智努力可能主要集中在数学问题和设计问题上，但是有必要强调穷举/遍历部分的重要性。因为穷举和遍历只有一个工作环节：定义问题和解空间。而有时换了一个定义，问题就相当于被解决了。譬如说一些最大化最小值问题（譬如lc 1552），直接的思路往往是从原问题的输入入手，但是如果把问题转换为在原问题的解空间查找一个符合要求的值，问题就会变得容易许多。

## （暴力）搜索
正如我们所说，一个算法问题很难避开穷举/遍历的环节，而搜索是纯粹依靠穷举的算法，所以它就能成为很多算法的组成部分，我们不得不优先考虑。

### 二分搜索
二分法的重要性体现在两个方面：
* 它解决的是在一组元素中找到符合要求的某个元素这类问题。这个问题太过基础和普遍，所以它的解法很重要。（二分法需要数组有序，排序也是另一个太过基础和普遍的问题）
* 它采用的分治思想也太过有用。

但是这么基础的二分法，要想轻松写出bug-free的代码也是困难的（参考维基对二分法的历史介绍）。尤其是在需要写二分法的一些变体时，譬如有重复元素时是返回最左侧或是最右侧的index。
针对这些变体有几个注意点：
1. 循环要能够（在只有两个元素的情况下）结束。譬如说以下代码想要实现查找最右侧元素（如果元素有重复查找index最大的那个）：
```
lo, hi = 0, n-1
while lo < hi:
    mid = (lo+hi) // 2
    if arr[mid] <= target:
        lo = mid
    else:
        hi = mid-1
```
可以发现如果在\[0,1\]里查0，lo,hi,mid会分别始终等于0,1,0，无限循环。
导致问题的原因是在if的两个分支中，hi确定会减少，但是lo却可能不变。因此解决方案是让`mid=(lo+hi+1) // 2`，这样if的两个分支在每次循环都一定会缩小区间的范围。
2. lo和hi选择开区间还是闭区间对于mid的运算有影响，因此对循环的结束和分支的写法有影响。而根据[Dijkstra的建议](https://www.cs.utexas.edu/users/EWD/transcriptions/EWD08xx/EWD831.html)，左闭右开区间是更好的选择。至少它能减少一个检查（譬如查找>=target的最小元素，当返回n-1时必须要检查这个元素是不是满足条件的最小元素——当然也可以在一开始检查，`if arr[n-1]<target: return n`，但这个检查是免不了的），不过这也就需要在函数的规格中确定当不存在所求元素时返回n而不是-1。
3. `mid=(lo+hi+1) // 2`这种写法在用整型的语言中是错误的（Java近些年被发现的错误，这可能导致溢出），但是在Python中是可以的，因为Python中整数没有精度限制。

除了上文这种记录区间左端点和右端点的写法，二分法还有一种等价的写法，通过记录区间的左端点和区间长度来计算中点。C++ STL里的lower_bound()和upper_bound()即是使用后一种。

#### 解空间上（区间）的二分搜索（浮点数）
之前我们提到遍历也可以发生在解空间，因此如果解空间是有序的我们也可以采用二分搜索。譬如我们提到的最大化最小值问题。其中有一点要注意：如果是求解一个实数，我们只能用指定一个误差精度，当`hi-lo < eps`时结束搜索。而eps的设置不能过小，因为浮点数有精度丢失的问题，过小的话可能eps被当成0，导致循环不会结束。


### 路径搜索
二分搜索能运用的场景是：给定的有序集合中找某个特定元素。但是，如果我们要搜索的是一个序列，而集合并没有事先给定，只给定了序列的生成方法，如何在未给定的序列集合中找到我们想要的呢？

那就只能一边生成一边搜索了。我们常用的深度优先搜索（DFS）或者广度优先搜索（BFS）既是搜索法也是遍历法。

但是在讨论BFS和DFS之前，我们必须强调这种路径搜索的运用范围：
1. 只能在图上使用。不像二分搜索还能在一个区间中搜索，BFS和DFS只能用在图这样的离散结构上。如果这个图是有向无环图（DAG）或者树那是最好不过；如果是一般的图，还需要记录访问过的节点以免无限循环。
2. DFS可以用来搜索任意满足条件的解（非最优），BFS（或者UCS,A*）可以用来搜索最优解。但是，它们没法处理最“差”解（譬如最长路径）这样的问题。最长路径缺少最短路径的一个重要性质：假如S到D的最短路径是S->A->B->C->D，那S->A一定是S到A的最短路径，S->A->B一定是S到B的最短路径，S->A->B->C一定是S到C的最短路径。最短路径中任一中间节点X都在源点到其的最短路径上。也可以说最短路径一定是由最短路径扩张而成的。或者说，其他节点的最短路径对于决定之后节点的最短路径提供了有益的信息。而最长路径不具有这个性质。事实上，对于一般的图而言，最长路径是一个NP完全问题。（当如对于DAG和树来说不是）
3. 如果是有权重的图，存在负权重时需要特殊对待。

#### 一般框架
```
frontier = some datastructe
explored = set()
while frontier is not empty:
    node = frontier.pop()
    if node is a desired solution: return node
    explored.add(node)
    for child in node.successors:
        if child not in frontier or explored:
            frontier.push(child)
return no solution
```

node这里指的是搜索树的节点，而不是问题的节点（如果问题是张图），一般会包含状态和cost。状态有时候可能会比较占资源，譬如说状态要记录已经走过的路径，因为节点数可能成指数增长，状态尽量小一点是很有意义的。

explored的存在完全是为了防止无限循环，如果是树就不需要记录explored。

根据搜索法的不同，frontier会采用不同的数据结构。DFS会用stack，BFS用queue，而UCS会用priority queue。

#### DFS, BFS, UCS
虽然这三者都是经典的算法，但是DFS更常用一些。因为DFS更适合遍历，因为通常它的空间复杂度更低（想象一下遍历二叉树时空间复杂度只有O(树高度)）。而且，DFS可以用递归写，利用函数栈隐式地使用栈。所以当问题需要遍历某种序列的集合时，DFS是首选，譬如生成一组数的所有排列/组合。

值得注意的是，搜索是搜索，遍历是遍历，不能因为搜索的方法也可以用于遍历就把两者混同。毕竟谁也不会把二分搜索说成是一种遍历的方式。我们说搜索法也可以用于遍历有两种含义：
1. 搜索法可以直接用于遍历解空间上的所有解。当某个搜索算法搜到一个解时不返回，而是继续搜索下一个解，那么就可以用来遍历所有解。
2. 搜索法的思想可以解决树的遍历问题，譬如我们可以用DFS和BFS的思想来遍历二叉树。因为搜索法最终也是在搜索树中查找叶子节点，到达叶子节点通常也必须经过中间节点，所以遍历叶子节点（解）最终也会遍历所有节点。

但毕竟两者不是同一个概念，也就会有以下差别：
1. 如果是解空间的遍历，可以针对中间节点进行优化，譬如说剪枝，或者记录历史搜索结果。后者可以考虑一个象棋的AI，它记录了某些致胜残局和对应的分数，搜索只要搜索到某步能导致致胜局面，就能得知是否获胜、获得几分，不用非要继续搜索把残局里的后续行动都搜索一遍。而树的遍历显然是不能跳过任何一个节点的，无论是中间节点还是叶子节点。
2. 对数据结构的遍历自然有一个顺序问题，DFS和BFS的思想只是两种特定顺序（先序遍历和层次遍历）的遍历方式，还有其它顺序的遍历算法(譬如说中序遍历），但是这些算法并不能用来搜索。





### 局部搜索
牛顿法

遗传算法

梯度下降